{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots = True\n",
    "\n",
    "# Load result csv file\n",
    "df = pd.read_csv('results.csv') # Results file has columns: Name,Mean,MeanLB,MeanUB,Stddev,StddevLB,StddevUB\n",
    "\n",
    "# Get dataset from name\n",
    "datasets = ['short', 'medium', 'long', 'extreme']\n",
    "dataset_to_size = {'short': 100, 'medium': 1000, 'long': 10000, 'extreme': 100000}\n",
    "data_qualifier = ['_1_ms/','_10_ms/','_100_ms/','_1000_ms/', '_0_2_ms/','_0_200_ms/','_0_20_ms/','_0_2000_ms/','_1000/', '_100/', '_10/', '_1/']\n",
    "distribution = ['uniform', 'constant', 'exponential']\n",
    "algos = ['delayedReduce', 'delayedTreeReduce', 'delayedFoldLReduce', 'delayedFoldRReduce']\n",
    "df['Dataset'] = df['Name'].apply(lambda x: next((d for d in datasets if d in x), None))\n",
    "df['Size'] = df['Dataset'].apply(lambda x: dataset_to_size[x])\n",
    "df['Qualifier'] = df['Name'].apply(lambda x: next((q for q in data_qualifier if q in x), None))\n",
    "df['Qualifier'] = df['Qualifier'].apply(lambda x: x.replace('_ms', '')) # remove ms part\n",
    "df['Qualifier'] = df['Qualifier'].apply(lambda x: x.replace('/', '')) # remove slash\n",
    "df['Qualifier'] = df['Qualifier'].apply(lambda x: x.replace('0_2', '1')) # replace '0_2' with 1, '0_20' with 10, '0_200' with 100, '0_2000' with 1000\n",
    "df['Full_name'] = df['Name'].apply(lambda x: x.split('/')[1]) # full name is part after first slash\n",
    "df['Distribution'] = df['Name'].apply(lambda x: next((d for d in distribution if d in x), None))\n",
    "df['Algo'] = df['Name'].apply(lambda x: next((a for a in algos if a in x), None))\n",
    "df['Name'] = df['Name'].apply(lambda x: x.replace('benchmarks/', ''))\n",
    "\n",
    "\n",
    "# We plot the results, where in the same graph we want to compare the different algorithms \n",
    "# with one subplot per qualifier-distribution combination, with a line for each algorithm\n",
    "# On the x axis we have the dataset size, on the y axis the mean time, with error bars for the standard deviation\n",
    "\n",
    "\n",
    "# Unique qualifier-distribution combinations\n",
    "qual_dist_combinations = df[['Qualifier', 'Distribution']].drop_duplicates().sort_values(by=['Qualifier', 'Distribution'])\n",
    "\n",
    "# Plot results for each combination separately\n",
    "for qualifier, distribution in qual_dist_combinations.values:\n",
    "    subset = df[(df['Qualifier'] == qualifier) & (df['Distribution'] == distribution)]\n",
    "    full_names = subset['Full_name'].unique()\n",
    "    \n",
    "    plt.figure(figsize=(5, 4.5))\n",
    "    for algo in algos:\n",
    "        algo_data = subset[subset['Algo'] == algo]\n",
    "        plt.errorbar(algo_data['Size'], algo_data['Mean'], yerr=algo_data['Stddev'], label=algo, marker='o', capsize=5)\n",
    "    \n",
    "    plt.title(f'Dataset {full_names[0]}')\n",
    "    plt.xlabel('Dataset Size')\n",
    "    plt.ylabel('Mean Time')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(0.5*10**-2, 2*10**2)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_plots:\n",
    "        # Save plot as name\n",
    "        plt.savefig(f'{qualifier}_{distribution}.png')\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
